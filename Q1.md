This script implements a comprehensive **Data Preprocessing and Feature Engineering Pipeline** for building energy consumption time-series data. It is designed to handle raw Excel files, unify them into continuous time series, impute missing values, detect anomalies, and generate features suitable for machine learning models (e.g., Transformers or LSTMs).

Below is the summary of the methodology and key technical points, organized for academic writing in both English and Chinese.

---

### 1. Data Ingestion & Time-Alignment (数据摄入与时间对齐)

**Methodology:**
The pipeline first parses raw Excel files distributed by year and building type. It extracts metadata (building type, resolution) from file paths. It utilizes a "last-value-wins" strategy to handle duplicate timestamps within and across files. Finally, it aligns the data to a strict standard frequency grid (e.g., 5-min, 30-min, 1-hour) via reindexing, ensuring a continuous timeline without structural gaps.

**Key Points:**
*   **Resolution Inference:** Automatically detects sampling rates (5min/30min/1h).
*   **De-duplication:** Handles overlapping data entries by prioritizing the most recent records.
*   **Grid Alignment:** Reindexes data to a complete datetime index `pd.date_range` to explicitly identify missing timestamps.

**中文摘要：**
该流程首先解析按年份和建筑类型分布的原始Excel文件，并从路径中提取元数据（建筑类型、分辨率）。它采用“最新值优先”的策略处理文件内部及文件间的重复时间戳。最后，通过重索引（Reindexing）将数据对齐到严格的标准频率网格（如5分钟、30分钟、1小时），从而确保时间轴连续且无结构性断点。

---

### 2. Hybrid Missing Value Imputation (混合缺失值插补)

**Methodology:**
A two-stage hybrid strategy is employed to handle missing data (`NaN`) and invalid measurements (negative values):
1.  **Short Gaps:** Small chunks of missing data (step size $\le$ 2 for 5-min data) are filled using linear interpolation to preserve local continuity.
2.  **Long Gaps:** Larger gaps are imputed using **STL (Seasonal-Trend decomposition using LoESS)**. The script fits an STL model on linearly filled data to extract Trend and Seasonality. It then regenerates the missing values by combining the extracted Trend, Seasonality, and random noise (derived from the distribution of residuals in the training set).

**Key Points:**
*   **Robustness:** Prevents linear interpolation from creating unrealistic "straight lines" over long outage periods.
*   **STL Synthesis:** Reconstructs data based on the underlying periodicity of building energy usage.

**中文摘要：**
针对缺失数据（NaN）和无效测量值（负值），采用了两阶段混合策略：
1.  **短缺口：** 对于微小的缺失块（如5分钟数据中步长$\le$2），使用线性插值以保持局部连续性。
2.  **长缺口：** 较大的缺失块采用 **STL（基于LoESS的季节-趋势分解）** 进行插补。脚本在初步填充的数据上拟合STL模型以提取趋势和季节性，然后结合趋势项、季节项以及从训练集残差分布中采样的随机噪声来重构缺失值。

---

### 3. Cyclical Temporal Feature Engineering (周期性时间特征工程)

**Methodology:**
To enable machine learning models to capture temporal dependencies, the script explicitly encodes time information into continuous variables using trigonometric transformations.

**Key Points:**
*   **Encodings:** Converts Minute-of-Day, Day-of-Week, and Day-of-Year into Sine and Cosine pairs.
*   **Mathematical Logic:** $x_{sin} = \sin(\frac{2\pi t}{T})$, $x_{cos} = \cos(\frac{2\pi t}{T})$. This ensures that the model understands that "23:59" and "00:00" are close to each other.

**中文摘要：**
为了使机器学习模型能够捕捉时间依赖性，脚本利用三角函数变换将时间信息显式编码为连续变量。具体将“分钟-天”、“天-周”和“天-年”转换为正弦（Sine）和余弦（Cosine）对。这种方法确保了模型能够理解时间的周期性（例如，23:59和00:00在数值空间上是紧邻的）。

---

### 4. Anomaly Detection (异常检测)

**Methodology:**
The script generates binary masks to label potential anomalies without removing them, allowing the model to decide how to handle them (or for use as auxiliary tasks).
1.  **Ramp Events:** Detects sudden spikes by calculating the absolute first-order difference ($|y_t - y_{t-1}|$). Values exceeding the 99.9th percentile (calculated on the training set) are flagged.
2.  **Statistical Outliers:** Uses STL decomposition residuals. Points where the residual deviates from the median by more than $K \times \text{MAD}$ (Median Absolute Deviation) are flagged (where $K=8.0$).

**中文摘要：**
脚本生成二进制掩码来标记潜在异常而非直接删除，允许后续模型自主处理：
1.  **爬坡事件（Ramp Events）：** 通过计算一阶差分绝对值检测突变。超过训练集99.9%分位数的点被标记。
2.  **统计离群点：** 利用STL分解残差。当残差偏离中位数超过 $K$ 倍的MAD（中位数绝对偏差）时（此处$K=8.0$），标记为异常。

---

### 5. Data Leakage Prevention & Robust Scaling (防止数据泄露与鲁棒归一化)

**Methodology:**
Strict separation of training and testing data is enforced during preprocessing parameters calculation.
*   **Parameter Estimation:** Statistics for scaling (Median, IQR), anomaly thresholds (Ramp quantile), and noise generation (Residual Mean/Std) are derived **solely from the training set** (defined by `train_end`).
*   **Robust Scaler:** Uses `(Value - Median) / IQR` instead of Standard Scaler (Mean/Std) to minimize the impact of extreme outliers on the scaling process.

**中文摘要：**
在预处理参数计算过程中，强制执行训练集与测试集的严格分离。
*   **参数估计：** 归一化统计量（中位数、四分位距）、异常阈值（爬坡分位数）以及噪声生成参数（残差均值/标准差）**仅从训练集**（由 `train_end` 定义）中推导。
*   **鲁棒归一化：** 采用 `(值 - 中位数) / 四分位距` 的方式，替代传统的标准归一化（均值/方差），以最小化极端离群点对缩放过程的影响。

---

### 6. Implementation Efficiency (实现效率)

**Key Points:**
*   **Parallel Processing:** Utilizes `multiprocessing.ProcessPoolExecutor` to process different buildings and resolutions concurrently, significantly reducing IO-bound processing time.
*   **Output Formats:** Saves processed data as `.parquet` (efficient storage) and metadata as `.json` (reproducibility).

**中文摘要：**
利用 `multiprocessing` 模块并发处理不同的建筑和分辨率数据，显著减少了IO密集型的处理时间。处理后的数据保存为高效的 `.parquet` 格式，元参数保存为 `.json` 以确保可复现性。